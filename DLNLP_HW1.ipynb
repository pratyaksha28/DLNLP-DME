{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oy31eyByENQ",
        "outputId": "3634ac37-87d0-45aa-f6de-0e9eba5f2a80"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDVKqoy4zG9W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "8006d8c4-1891-4ab5-a9b9-f3d94080f4bb"
      },
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/DLNLP/OnlineNewsPopularity.csv\")\n",
        "df = df.iloc[:,1:]\n",
        "df "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timedelta</th>\n",
              "      <th>n_tokens_title</th>\n",
              "      <th>n_tokens_content</th>\n",
              "      <th>n_unique_tokens</th>\n",
              "      <th>n_non_stop_words</th>\n",
              "      <th>n_non_stop_unique_tokens</th>\n",
              "      <th>num_hrefs</th>\n",
              "      <th>num_self_hrefs</th>\n",
              "      <th>num_imgs</th>\n",
              "      <th>num_videos</th>\n",
              "      <th>average_token_length</th>\n",
              "      <th>num_keywords</th>\n",
              "      <th>data_channel_is_lifestyle</th>\n",
              "      <th>data_channel_is_entertainment</th>\n",
              "      <th>data_channel_is_bus</th>\n",
              "      <th>data_channel_is_socmed</th>\n",
              "      <th>data_channel_is_tech</th>\n",
              "      <th>data_channel_is_world</th>\n",
              "      <th>kw_min_min</th>\n",
              "      <th>kw_max_min</th>\n",
              "      <th>kw_avg_min</th>\n",
              "      <th>kw_min_max</th>\n",
              "      <th>kw_max_max</th>\n",
              "      <th>kw_avg_max</th>\n",
              "      <th>kw_min_avg</th>\n",
              "      <th>kw_max_avg</th>\n",
              "      <th>kw_avg_avg</th>\n",
              "      <th>self_reference_min_shares</th>\n",
              "      <th>self_reference_max_shares</th>\n",
              "      <th>self_reference_avg_sharess</th>\n",
              "      <th>weekday_is_monday</th>\n",
              "      <th>weekday_is_tuesday</th>\n",
              "      <th>weekday_is_wednesday</th>\n",
              "      <th>weekday_is_thursday</th>\n",
              "      <th>weekday_is_friday</th>\n",
              "      <th>weekday_is_saturday</th>\n",
              "      <th>weekday_is_sunday</th>\n",
              "      <th>is_weekend</th>\n",
              "      <th>LDA_00</th>\n",
              "      <th>LDA_01</th>\n",
              "      <th>LDA_02</th>\n",
              "      <th>LDA_03</th>\n",
              "      <th>LDA_04</th>\n",
              "      <th>global_subjectivity</th>\n",
              "      <th>global_sentiment_polarity</th>\n",
              "      <th>global_rate_positive_words</th>\n",
              "      <th>global_rate_negative_words</th>\n",
              "      <th>rate_positive_words</th>\n",
              "      <th>rate_negative_words</th>\n",
              "      <th>avg_positive_polarity</th>\n",
              "      <th>min_positive_polarity</th>\n",
              "      <th>max_positive_polarity</th>\n",
              "      <th>avg_negative_polarity</th>\n",
              "      <th>min_negative_polarity</th>\n",
              "      <th>max_negative_polarity</th>\n",
              "      <th>title_subjectivity</th>\n",
              "      <th>title_sentiment_polarity</th>\n",
              "      <th>abs_title_subjectivity</th>\n",
              "      <th>abs_title_sentiment_polarity</th>\n",
              "      <th>shares</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>731.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>0.663594</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.815385</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.680365</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>496.0</td>\n",
              "      <td>496.0</td>\n",
              "      <td>496.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500331</td>\n",
              "      <td>0.378279</td>\n",
              "      <td>0.040005</td>\n",
              "      <td>0.041263</td>\n",
              "      <td>0.040123</td>\n",
              "      <td>0.521617</td>\n",
              "      <td>0.092562</td>\n",
              "      <td>0.045662</td>\n",
              "      <td>0.013699</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.378636</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.70</td>\n",
              "      <td>-0.350000</td>\n",
              "      <td>-0.600</td>\n",
              "      <td>-0.200000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>-0.187500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>731.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>0.604743</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.791946</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.913725</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.799756</td>\n",
              "      <td>0.050047</td>\n",
              "      <td>0.050096</td>\n",
              "      <td>0.050101</td>\n",
              "      <td>0.050001</td>\n",
              "      <td>0.341246</td>\n",
              "      <td>0.148948</td>\n",
              "      <td>0.043137</td>\n",
              "      <td>0.015686</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.286915</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.70</td>\n",
              "      <td>-0.118750</td>\n",
              "      <td>-0.125</td>\n",
              "      <td>-0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>731.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>211.0</td>\n",
              "      <td>0.575130</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.663866</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.393365</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>918.0</td>\n",
              "      <td>918.0</td>\n",
              "      <td>918.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.217792</td>\n",
              "      <td>0.033334</td>\n",
              "      <td>0.033351</td>\n",
              "      <td>0.033334</td>\n",
              "      <td>0.682188</td>\n",
              "      <td>0.702222</td>\n",
              "      <td>0.323333</td>\n",
              "      <td>0.056872</td>\n",
              "      <td>0.009479</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.495833</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>-0.466667</td>\n",
              "      <td>-0.800</td>\n",
              "      <td>-0.133333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>731.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>531.0</td>\n",
              "      <td>0.503788</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.665635</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.404896</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.028573</td>\n",
              "      <td>0.419300</td>\n",
              "      <td>0.494651</td>\n",
              "      <td>0.028905</td>\n",
              "      <td>0.028572</td>\n",
              "      <td>0.429850</td>\n",
              "      <td>0.100705</td>\n",
              "      <td>0.041431</td>\n",
              "      <td>0.020716</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.385965</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.80</td>\n",
              "      <td>-0.369697</td>\n",
              "      <td>-0.600</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>731.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1072.0</td>\n",
              "      <td>0.415646</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.540890</td>\n",
              "      <td>19.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.682836</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>545.0</td>\n",
              "      <td>16000.0</td>\n",
              "      <td>3151.157895</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.028633</td>\n",
              "      <td>0.028794</td>\n",
              "      <td>0.028575</td>\n",
              "      <td>0.028572</td>\n",
              "      <td>0.885427</td>\n",
              "      <td>0.513502</td>\n",
              "      <td>0.281003</td>\n",
              "      <td>0.074627</td>\n",
              "      <td>0.012127</td>\n",
              "      <td>0.860215</td>\n",
              "      <td>0.139785</td>\n",
              "      <td>0.411127</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>1.00</td>\n",
              "      <td>-0.220192</td>\n",
              "      <td>-0.500</td>\n",
              "      <td>-0.050000</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39639</th>\n",
              "      <td>8.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>346.0</td>\n",
              "      <td>0.529052</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.684783</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.523121</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>671.0</td>\n",
              "      <td>173.125</td>\n",
              "      <td>26900.0</td>\n",
              "      <td>843300.0</td>\n",
              "      <td>374962.500000</td>\n",
              "      <td>2514.742857</td>\n",
              "      <td>4004.342857</td>\n",
              "      <td>3031.115764</td>\n",
              "      <td>11400.0</td>\n",
              "      <td>48000.0</td>\n",
              "      <td>37033.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.025038</td>\n",
              "      <td>0.025001</td>\n",
              "      <td>0.151701</td>\n",
              "      <td>0.025000</td>\n",
              "      <td>0.773260</td>\n",
              "      <td>0.482679</td>\n",
              "      <td>0.141964</td>\n",
              "      <td>0.037572</td>\n",
              "      <td>0.014451</td>\n",
              "      <td>0.722222</td>\n",
              "      <td>0.277778</td>\n",
              "      <td>0.333791</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.75</td>\n",
              "      <td>-0.260000</td>\n",
              "      <td>-0.500</td>\n",
              "      <td>-0.125000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39640</th>\n",
              "      <td>8.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>328.0</td>\n",
              "      <td>0.696296</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.885057</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>4.405488</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>616.0</td>\n",
              "      <td>184.000</td>\n",
              "      <td>6500.0</td>\n",
              "      <td>843300.0</td>\n",
              "      <td>192985.714286</td>\n",
              "      <td>1664.267857</td>\n",
              "      <td>5470.168651</td>\n",
              "      <td>3411.660830</td>\n",
              "      <td>2100.0</td>\n",
              "      <td>2100.0</td>\n",
              "      <td>2100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.029349</td>\n",
              "      <td>0.028575</td>\n",
              "      <td>0.231866</td>\n",
              "      <td>0.681635</td>\n",
              "      <td>0.028575</td>\n",
              "      <td>0.564374</td>\n",
              "      <td>0.194249</td>\n",
              "      <td>0.039634</td>\n",
              "      <td>0.009146</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>0.374825</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.70</td>\n",
              "      <td>-0.211111</td>\n",
              "      <td>-0.400</td>\n",
              "      <td>-0.100000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39641</th>\n",
              "      <td>8.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>442.0</td>\n",
              "      <td>0.516355</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.644128</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.076923</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>691.0</td>\n",
              "      <td>168.250</td>\n",
              "      <td>6200.0</td>\n",
              "      <td>843300.0</td>\n",
              "      <td>295850.000000</td>\n",
              "      <td>1753.882353</td>\n",
              "      <td>6880.687034</td>\n",
              "      <td>4206.439195</td>\n",
              "      <td>1400.0</td>\n",
              "      <td>1400.0</td>\n",
              "      <td>1400.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.159004</td>\n",
              "      <td>0.025025</td>\n",
              "      <td>0.025207</td>\n",
              "      <td>0.643794</td>\n",
              "      <td>0.146970</td>\n",
              "      <td>0.510296</td>\n",
              "      <td>0.024609</td>\n",
              "      <td>0.033937</td>\n",
              "      <td>0.024887</td>\n",
              "      <td>0.576923</td>\n",
              "      <td>0.423077</td>\n",
              "      <td>0.307273</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.50</td>\n",
              "      <td>-0.356439</td>\n",
              "      <td>-0.800</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>1900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39642</th>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>682.0</td>\n",
              "      <td>0.539493</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.692661</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.975073</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>843300.0</td>\n",
              "      <td>254600.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3384.316871</td>\n",
              "      <td>1777.895883</td>\n",
              "      <td>452.0</td>\n",
              "      <td>452.0</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.040004</td>\n",
              "      <td>0.040003</td>\n",
              "      <td>0.839987</td>\n",
              "      <td>0.040002</td>\n",
              "      <td>0.040004</td>\n",
              "      <td>0.358578</td>\n",
              "      <td>-0.008066</td>\n",
              "      <td>0.020528</td>\n",
              "      <td>0.023460</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.236851</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.50</td>\n",
              "      <td>-0.205246</td>\n",
              "      <td>-0.500</td>\n",
              "      <td>-0.012500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39643</th>\n",
              "      <td>8.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>157.0</td>\n",
              "      <td>0.701987</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.471338</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>23.500</td>\n",
              "      <td>205600.0</td>\n",
              "      <td>843300.0</td>\n",
              "      <td>366200.000000</td>\n",
              "      <td>3035.080555</td>\n",
              "      <td>3613.512953</td>\n",
              "      <td>3296.909481</td>\n",
              "      <td>2100.0</td>\n",
              "      <td>2100.0</td>\n",
              "      <td>2100.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.050001</td>\n",
              "      <td>0.799339</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.050659</td>\n",
              "      <td>0.050001</td>\n",
              "      <td>0.517893</td>\n",
              "      <td>0.104892</td>\n",
              "      <td>0.063694</td>\n",
              "      <td>0.012739</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.247338</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.50</td>\n",
              "      <td>-0.200000</td>\n",
              "      <td>-0.200</td>\n",
              "      <td>-0.200000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>1300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>39644 rows Ã— 60 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        timedelta   n_tokens_title  ...   abs_title_sentiment_polarity   shares\n",
              "0           731.0             12.0  ...                       0.187500      593\n",
              "1           731.0              9.0  ...                       0.000000      711\n",
              "2           731.0              9.0  ...                       0.000000     1500\n",
              "3           731.0              9.0  ...                       0.000000     1200\n",
              "4           731.0             13.0  ...                       0.136364      505\n",
              "...           ...              ...  ...                            ...      ...\n",
              "39639         8.0             11.0  ...                       0.000000     1800\n",
              "39640         8.0             12.0  ...                       1.000000     1900\n",
              "39641         8.0             10.0  ...                       0.136364     1900\n",
              "39642         8.0              6.0  ...                       0.000000     1100\n",
              "39643         8.0             10.0  ...                       0.250000     1300\n",
              "\n",
              "[39644 rows x 60 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1foAeGXlh7IZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3f81999-3a6c-4f9d-e0b9-a07a440e2d0e"
      },
      "source": [
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(1)\n",
        "from tensorflow.python.keras.layers import Dense, BatchNormalization\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "import keras\n",
        "from keras.models import load_model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InXs6Ffbog91"
      },
      "source": [
        "k = 30000\n",
        "trainX = df.iloc[:k,:59].values\n",
        "trainY = df.iloc[:k,59].values\n",
        "testX = df.iloc[k:,:59].values\n",
        "testY = df.iloc[k:,59].values\n",
        "\n",
        "trainY = trainY.reshape(-1,1)\n",
        "testY = testY.reshape(-1,1)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "trainX = scaler.fit_transform(trainX)\n",
        "testX = scaler.transform(testX)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "trainY= scaler.fit_transform(trainY)\n",
        "testY = scaler.transform(testY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CPbmQr-iiGn"
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def rmse(y_true, y_pred):\n",
        "        return K.sqrt(K.mean(K.square(y_pred - y_true))) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4wqL96eIjY75",
        "outputId": "f41acc7a-25cc-429e-b12f-da5f107cd31d"
      },
      "source": [
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(59, input_dim=59, kernel_initializer='normal', activation='tanh'))\n",
        "model.add(Dense(512, activation='tanh'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss=rmse, optimizer= opt, metrics=[rmse])\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
        "history=model.fit(trainX, trainY, epochs=100, batch_size=64, verbose=1, validation_split=0.1)\n",
        "\n",
        "print(history.history.keys())\n",
        "# \"Loss\"\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 59)                3540      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 512)               30720     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 34,773\n",
            "Trainable params: 34,773\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0148 - rmse: 0.0148 - val_loss: 0.0081 - val_rmse: 0.0081\n",
            "Epoch 2/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0112 - rmse: 0.0112 - val_loss: 0.0087 - val_rmse: 0.0087\n",
            "Epoch 3/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0107 - rmse: 0.0107 - val_loss: 0.0071 - val_rmse: 0.0071\n",
            "Epoch 4/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0102 - rmse: 0.0102 - val_loss: 0.0074 - val_rmse: 0.0074\n",
            "Epoch 5/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0100 - rmse: 0.0100 - val_loss: 0.0068 - val_rmse: 0.0068\n",
            "Epoch 6/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0099 - rmse: 0.0099 - val_loss: 0.0069 - val_rmse: 0.0069\n",
            "Epoch 7/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0097 - rmse: 0.0097 - val_loss: 0.0066 - val_rmse: 0.0066\n",
            "Epoch 8/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0095 - rmse: 0.0095 - val_loss: 0.0069 - val_rmse: 0.0069\n",
            "Epoch 9/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.0071 - val_rmse: 0.0071\n",
            "Epoch 10/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0095 - rmse: 0.0095 - val_loss: 0.0065 - val_rmse: 0.0065\n",
            "Epoch 11/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0094 - rmse: 0.0094 - val_loss: 0.0065 - val_rmse: 0.0065\n",
            "Epoch 12/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.0064 - val_rmse: 0.0064\n",
            "Epoch 13/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0094 - rmse: 0.0094 - val_loss: 0.0065 - val_rmse: 0.0065\n",
            "Epoch 14/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.0064 - val_rmse: 0.0064\n",
            "Epoch 15/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.0064 - val_rmse: 0.0064\n",
            "Epoch 16/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.0064 - val_rmse: 0.0064\n",
            "Epoch 17/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.0071 - val_rmse: 0.0071\n",
            "Epoch 18/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.0065 - val_rmse: 0.0065\n",
            "Epoch 19/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.0068 - val_rmse: 0.0069\n",
            "Epoch 20/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0094 - rmse: 0.0094 - val_loss: 0.0064 - val_rmse: 0.0064\n",
            "Epoch 21/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.0064 - val_rmse: 0.0064\n",
            "Epoch 22/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0065 - val_rmse: 0.0065\n",
            "Epoch 23/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0094 - rmse: 0.0094 - val_loss: 0.0063 - val_rmse: 0.0063\n",
            "Epoch 24/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0064 - val_rmse: 0.0064\n",
            "Epoch 25/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.0064 - val_rmse: 0.0064\n",
            "Epoch 26/100\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0064 - val_rmse: 0.0064\n",
            "Epoch 27/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.0064 - val_rmse: 0.0064\n",
            "Epoch 28/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0064 - val_rmse: 0.0064\n",
            "Epoch 29/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0063 - val_rmse: 0.0063\n",
            "Epoch 30/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0064 - val_rmse: 0.0064\n",
            "Epoch 31/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.0067 - val_rmse: 0.0067\n",
            "Epoch 32/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0064 - val_rmse: 0.0064\n",
            "Epoch 33/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.0063 - val_rmse: 0.0063\n",
            "Epoch 34/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0063 - val_rmse: 0.0064\n",
            "Epoch 35/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.0063 - val_rmse: 0.0063\n",
            "Epoch 36/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.0064 - val_rmse: 0.0064\n",
            "Epoch 37/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0091 - rmse: 0.0091 - val_loss: 0.0065 - val_rmse: 0.0065\n",
            "Epoch 38/100\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.0063 - val_rmse: 0.0063\n",
            "Epoch 39/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0065 - val_rmse: 0.0065\n",
            "Epoch 40/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0063 - val_rmse: 0.0064\n",
            "Epoch 41/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.0063 - val_rmse: 0.0063\n",
            "Epoch 42/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0064 - val_rmse: 0.0064\n",
            "Epoch 43/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0064 - val_rmse: 0.0065\n",
            "Epoch 44/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0067 - val_rmse: 0.0067\n",
            "Epoch 45/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.0064 - val_rmse: 0.0064\n",
            "Epoch 46/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0064 - val_rmse: 0.0064\n",
            "Epoch 47/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.0064 - val_rmse: 0.0064\n",
            "Epoch 48/100\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0067 - val_rmse: 0.0067\n",
            "Epoch 49/100\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.0091 - rmse: 0.0091 - val_loss: 0.0066 - val_rmse: 0.0066\n",
            "Epoch 50/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.0065 - val_rmse: 0.0065\n",
            "Epoch 51/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0063 - val_rmse: 0.0063\n",
            "Epoch 52/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0063 - val_rmse: 0.0063\n",
            "Epoch 53/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0065 - val_rmse: 0.0065\n",
            "Epoch 54/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0064 - val_rmse: 0.0064\n",
            "Epoch 55/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0063 - val_rmse: 0.0064\n",
            "Epoch 56/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0066 - val_rmse: 0.0066\n",
            "Epoch 57/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0091 - rmse: 0.0091 - val_loss: 0.0063 - val_rmse: 0.0063\n",
            "Epoch 58/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0065 - val_rmse: 0.0065\n",
            "Epoch 59/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0063 - val_rmse: 0.0063\n",
            "Epoch 60/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.0064 - val_rmse: 0.0064\n",
            "Epoch 61/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.0068 - val_rmse: 0.0068\n",
            "Epoch 62/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0065 - val_rmse: 0.0065\n",
            "Epoch 63/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.0064 - val_rmse: 0.0064\n",
            "Epoch 64/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.0063 - val_rmse: 0.0063\n",
            "Epoch 65/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0064 - val_rmse: 0.0064\n",
            "Epoch 66/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.0063 - val_rmse: 0.0063\n",
            "Epoch 67/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0064 - val_rmse: 0.0064\n",
            "Epoch 68/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0065 - val_rmse: 0.0065\n",
            "Epoch 69/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0063 - val_rmse: 0.0063\n",
            "Epoch 70/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.0064 - val_rmse: 0.0064\n",
            "Epoch 71/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0063 - val_rmse: 0.0063\n",
            "Epoch 72/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0091 - rmse: 0.0091 - val_loss: 0.0063 - val_rmse: 0.0064\n",
            "Epoch 73/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0063 - val_rmse: 0.0063\n",
            "Epoch 74/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0090 - rmse: 0.0090 - val_loss: 0.0064 - val_rmse: 0.0064\n",
            "Epoch 75/100\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0063 - val_rmse: 0.0063\n",
            "Epoch 76/100\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.0064 - val_rmse: 0.0064\n",
            "Epoch 77/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0091 - rmse: 0.0091 - val_loss: 0.0063 - val_rmse: 0.0063\n",
            "Epoch 78/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0067 - val_rmse: 0.0067\n",
            "Epoch 79/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0091 - rmse: 0.0091 - val_loss: 0.0064 - val_rmse: 0.0064\n",
            "Epoch 80/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.0064 - val_rmse: 0.0065\n",
            "Epoch 81/100\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.0091 - rmse: 0.0091 - val_loss: 0.0063 - val_rmse: 0.0063\n",
            "Epoch 82/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0091 - rmse: 0.0091 - val_loss: 0.0067 - val_rmse: 0.0067\n",
            "Epoch 83/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0091 - rmse: 0.0091 - val_loss: 0.0063 - val_rmse: 0.0063\n",
            "Epoch 84/100\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0065 - val_rmse: 0.0065\n",
            "Epoch 85/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.0063 - val_rmse: 0.0063\n",
            "Epoch 86/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0065 - val_rmse: 0.0065\n",
            "Epoch 87/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0093 - rmse: 0.0093 - val_loss: 0.0064 - val_rmse: 0.0064\n",
            "Epoch 88/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0063 - val_rmse: 0.0063\n",
            "Epoch 89/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0064 - val_rmse: 0.0064\n",
            "Epoch 90/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0065 - val_rmse: 0.0065\n",
            "Epoch 91/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0065 - val_rmse: 0.0065\n",
            "Epoch 92/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0063 - val_rmse: 0.0063\n",
            "Epoch 93/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0063 - val_rmse: 0.0063\n",
            "Epoch 94/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0063 - val_rmse: 0.0063\n",
            "Epoch 95/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0064 - val_rmse: 0.0064\n",
            "Epoch 96/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0063 - val_rmse: 0.0063\n",
            "Epoch 97/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0063 - val_rmse: 0.0063\n",
            "Epoch 98/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0091 - rmse: 0.0091 - val_loss: 0.0063 - val_rmse: 0.0063\n",
            "Epoch 99/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0092 - rmse: 0.0092 - val_loss: 0.0064 - val_rmse: 0.0064\n",
            "Epoch 100/100\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.0090 - rmse: 0.0090 - val_loss: 0.0063 - val_rmse: 0.0063\n",
            "dict_keys(['loss', 'rmse', 'val_loss', 'val_rmse'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWloA3-hWbm-"
      },
      "source": [
        "#model.save(\"/content/drive/MyDrive/DLNLP/my_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0I5WKo7WW6n_",
        "outputId": "9f6eac79-c0e2-4309-9b83-5d84f5a759b0"
      },
      "source": [
        "predictions = model.predict(testX)\n",
        "print(rmse(testY,predictions))\n",
        "print(rmse(scaler.inverse_transform(testY),scaler.inverse_transform(predictions)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0.00912883091675041, shape=(), dtype=float64)\n",
            "tf.Tensor(7698.3339811804535, shape=(), dtype=float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewe9Hi64nfFz",
        "outputId": "f1b9b075-1790-44cc-c8bd-a6b093de6895"
      },
      "source": [
        "loaded_model = load_model(\"/content/drive/MyDrive/DLNLP/my_model.h5\",custom_objects={'rmse': rmse})\n",
        "predictions = loaded_model.predict(testX)\n",
        "\n",
        "print(rmse(testY,predictions))\n",
        "print(rmse(scaler.inverse_transform(testY),scaler.inverse_transform(predictions)))\n",
        "\n",
        "loaded_model.summary()\n",
        "\n",
        "\n",
        "# print(mean_absolute_error(testY, predictions))\n",
        "# print(mean_squared_error(testY, predictions))\n",
        "# print(math.sqrt(mean_squared_error(testY, predictions)))\n",
        "\n",
        "# predictions = scaler.inverse_transform(predictions)\n",
        "\n",
        "\n",
        "# print(mean_absolute_error(scaler.inverse_transform(testY), predictions))\n",
        "# print(mean_squared_error(scaler.inverse_transform(testY), predictions))\n",
        "# print(math.sqrt(mean_squared_error(scaler.inverse_transform(testY), predictions)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0.009100314421660531, shape=(), dtype=float64)\n",
            "tf.Tensor(7674.286048676699, shape=(), dtype=float64)\n",
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_96 (Dense)             (None, 59)                3540      \n",
            "_________________________________________________________________\n",
            "dense_97 (Dense)             (None, 512)               30720     \n",
            "_________________________________________________________________\n",
            "dense_98 (Dense)             (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 34,773\n",
            "Trainable params: 34,773\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNa2aOuFuSyJ"
      },
      "source": [
        "for layer in loaded_model.layers:\n",
        "    weights = layer.get_weights() \n",
        "    print(weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "_zfVKmwCock6",
        "outputId": "ac1de57d-6fc5-4052-9e60-b91ce5b6e5c7"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-1f8a688cae5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    }
  ]
}